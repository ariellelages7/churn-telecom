{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fbc8b90-6397-4035-8276-963ad29ef4af",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (82538336.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 5\u001b[1;36m\u001b[0m\n\u001b[1;33m    Neste projeto, eu desenvolvi uma solução de Ciência de Dados com o objetivo de prever o **churn de clientes** em uma empresa do setor de telecomunicações.\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Projeto de Ciência de Dados – Predição de Churn em Telecomunicações\n",
    "\n",
    "## 1. Contexto do Projeto\n",
    "\n",
    "Neste projeto, eu desenvolvi uma solução de Ciência de Dados com o objetivo de prever o **churn de clientes** em uma empresa do setor de telecomunicações.  \n",
    "O churn representa o cancelamento do serviço por parte do cliente e é um dos principais desafios estratégicos para empresas desse segmento, pois impacta diretamente a receita e os custos de aquisição de novos clientes.\n",
    "\n",
    "Empresas de telecom lidam com alta competitividade e margens cada vez mais pressionadas. Nesse contexto, **reter clientes é significativamente mais barato do que adquirir novos**, tornando a previsão de churn uma ferramenta essencial para apoiar decisões de negócio baseadas em dados.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Problema de Negócio\n",
    "\n",
    "O problema que busquei resolver foi:\n",
    "\n",
    "> **Como identificar, com antecedência, clientes com maior probabilidade de cancelar o serviço?**\n",
    "\n",
    "Ao prever o churn, a empresa pode:\n",
    "- Criar campanhas de retenção mais assertivas\n",
    "- Priorizar clientes de alto risco\n",
    "- Reduzir perdas financeiras\n",
    "- Melhorar a experiência do cliente\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Objetivo do Projeto\n",
    "\n",
    "O objetivo principal deste projeto foi **construir um modelo de machine learning capaz de prever se um cliente irá ou não entrar em churn**, com base em suas características contratuais, de uso e de perfil.\n",
    "\n",
    "Os objetivos específicos incluem:\n",
    "- Analisar o comportamento dos clientes\n",
    "- Identificar padrões associados ao churn\n",
    "- Preparar os dados adequadamente para modelagem\n",
    "- Treinar e avaliar um modelo preditivo\n",
    "- Apresentar visualizações claras dos resultados obtidos\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Base de Dados Utilizada\n",
    "\n",
    "Para o desenvolvimento do projeto, utilizei a base de dados **Churn Telecom**, que contém informações sobre clientes de uma empresa de telecomunicações, incluindo:\n",
    "- Dados demográficos\n",
    "- Informações de contrato\n",
    "- Serviços contratados\n",
    "- Histórico de cobrança\n",
    "- Indicador de churn\n",
    "\n",
    "Essa base é amplamente utilizada em estudos de churn e permite aplicar conceitos fundamentais de análise exploratória, pré-processamento e modelagem preditiva.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Abordagem Metodológica\n",
    "\n",
    "O projeto foi desenvolvido seguindo uma abordagem estruturada, composta pelas seguintes etapas:\n",
    "\n",
    "1. Entendimento do problema e do negócio  \n",
    "2. Análise exploratória dos dados  \n",
    "3. Tratamento e preparação dos dados  \n",
    "4. Construção do modelo de machine learning  \n",
    "5. Avaliação dos resultados  \n",
    "6. Visualização e interpretação dos insights  \n",
    "7. Conclusões e recomendações finais\n",
    "\n",
    "Cada etapa foi documentada de forma clara, com foco na interpretação dos dados e na justificativa das decisões tomadas ao longo do processo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3053b6ab-fd42-41cd-95e8-63c433ddf67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Coleta e Carregamento dos Dados\n",
    "\n",
    "Nesta etapa, eu carreguei a base `CHURN_TELECON.csv` e fiz uma inspeção inicial para entender:\n",
    "- o tamanho do dataset (linhas e colunas),\n",
    "- os tipos de dados,\n",
    "- a presença de valores ausentes,\n",
    "- possíveis inconsistências de categorização.\n",
    "\n",
    "Meu objetivo aqui foi validar a qualidade do dado antes de qualquer análise mais profunda ou modelagem, seguindo o princípio de que a qualidade da entrada impacta diretamente a qualidade do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90af5fca-782f-44d2-9653-ea8748e3b936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ajuste o caminho se necessário\n",
    "PATH = \"CHURN_TELECON.csv\"\n",
    "\n",
    "# Importante: essa base usa ';' como separador\n",
    "df = pd.read_csv(PATH, sep=\";\")\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f9f33e-681f-4229-ad8b-0d600c600e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tipos das colunas\n",
    "display(df.dtypes)\n",
    "\n",
    "# Checando duplicatas\n",
    "print(\"Linhas duplicadas (linha inteira):\", df.duplicated().sum())\n",
    "print(\"customerID duplicado:\", df[\"customerID\"].duplicated().sum())\n",
    "\n",
    "# Missing por coluna\n",
    "missing = df.isna().sum().sort_values(ascending=False)\n",
    "missing_pct = (df.isna().mean() * 100).sort_values(ascending=False)\n",
    "\n",
    "diagnostico_missing = pd.DataFrame({\n",
    "    \"missing_count\": missing,\n",
    "    \"missing_%\": missing_pct.round(2)\n",
    "})\n",
    "\n",
    "display(diagnostico_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268f571d-b65d-4655-bd97-6e0bb1583a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição do target (incluindo NaN)\n",
    "display(df[\"Churn\"].value_counts(dropna=False))\n",
    "\n",
    "# Plot simples da distribuição do churn (sem NaN)\n",
    "churn_counts = df[\"Churn\"].dropna().value_counts()\n",
    "plt.figure()\n",
    "plt.bar(churn_counts.index.astype(str), churn_counts.values)\n",
    "plt.title(\"Distribuição do Target (Churn)\")\n",
    "plt.xlabel(\"Churn\")\n",
    "plt.ylabel(\"Quantidade\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Proporção (%):\")\n",
    "display((df[\"Churn\"].dropna().value_counts(normalize=True) * 100).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acfbb50-e083-44b2-93ae-f547c8ddfb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Principais Problemas de Qualidade e Estratégia de Tratamento\n",
    "\n",
    "Nesta base, eu identifiquei três pontos importantes de qualidade:\n",
    "\n",
    "1. **Valores ausentes**: existem colunas com valores faltantes, incluindo o próprio target (`Churn`) em poucas linhas.\n",
    "2. **Inconsistência em categorias**: a variável `Genero` apresenta variações como `Male`, `M`, `f`, etc., o que exige padronização.\n",
    "3. **Campos vazios correlacionados**: observei casos em que `PhoneService` e `Pagamento_Mensal` aparecem vazios simultaneamente.  \n",
    "   Para evitar imputação arbitrária, eu usei uma estratégia guiada por regra: quando possível, estimei o pagamento mensal a partir de `Total_Pago` e `Tempo_como_Cliente`.\n",
    "\n",
    "Meu objetivo foi produzir um dataset consistente e pronto para modelagem, minimizando distorções e mantendo coerência de negócio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4890f3da-4ad7-47cb-9212-9535ac61dc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()\n",
    "\n",
    "# 1) Remover linhas sem target (não dá para treinar sem rótulo)\n",
    "df_clean = df_clean.dropna(subset=[\"Churn\"]).reset_index(drop=True)\n",
    "\n",
    "# 2) Padronizar Genero\n",
    "# - Normaliza strings (strip/lower)\n",
    "# - Mapeia variações\n",
    "def padroniza_genero(x):\n",
    "    if pd.isna(x):\n",
    "        return \"Unknown\"\n",
    "    x = str(x).strip().lower()\n",
    "    if x in [\"male\", \"m\"]:\n",
    "        return \"Male\"\n",
    "    if x in [\"female\", \"f\"]:\n",
    "        return \"Female\"\n",
    "    return \"Unknown\"\n",
    "\n",
    "df_clean[\"Genero\"] = df_clean[\"Genero\"].apply(padroniza_genero)\n",
    "\n",
    "# 3) PhoneService: missing vira categoria explícita\n",
    "df_clean[\"PhoneService\"] = df_clean[\"PhoneService\"].fillna(\"Unknown\")\n",
    "\n",
    "# 4) Pagamento_Mensal: imputação guiada por regra\n",
    "# Se Pagamento_Mensal é NaN e temos Total_Pago e Tempo_como_Cliente, estimamos:\n",
    "# Pagamento_Mensal_estimado = Total_Pago / max(Tempo_como_Cliente, 1)\n",
    "mask_pm = df_clean[\"Pagamento_Mensal\"].isna()\n",
    "\n",
    "df_clean.loc[mask_pm, \"Pagamento_Mensal\"] = (\n",
    "    df_clean.loc[mask_pm, \"Total_Pago\"] / df_clean.loc[mask_pm, \"Tempo_como_Cliente\"].clip(lower=1)\n",
    ")\n",
    "\n",
    "# Se ainda sobrar NaN (caso extremo), preenche com mediana\n",
    "df_clean[\"Pagamento_Mensal\"] = df_clean[\"Pagamento_Mensal\"].fillna(df_clean[\"Pagamento_Mensal\"].median())\n",
    "\n",
    "# 5) Checagem final de missing\n",
    "display(df_clean.isna().sum().sort_values(ascending=False))\n",
    "print(\"Shape final:\", df_clean.shape)\n",
    "\n",
    "display(df_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02df42c-d611-43ce-ac05-a7bc2207223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checando se não sobrou churn nulo\n",
    "print(\"Churn nulo após tratamento:\", df_clean[\"Churn\"].isna().sum())\n",
    "\n",
    "# Valores únicos para conferir padronização do Genero e PhoneService\n",
    "print(\"Genero - valores únicos:\", df_clean[\"Genero\"].unique())\n",
    "print(\"PhoneService - valores únicos:\", df_clean[\"PhoneService\"].unique())\n",
    "\n",
    "# Estatísticas rápidas dos numéricos\n",
    "display(df_clean[[\"Tempo_como_Cliente\", \"Pagamento_Mensal\", \"Total_Pago\", \"Idoso\"]].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3e52cf-fd2d-4a7f-8ae8-32e0b3ec14cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Análise Exploratória de Dados (EDA)\n",
    "\n",
    "Nesta etapa, eu realizei uma análise exploratória dos dados com o objetivo de compreender o comportamento dos clientes e identificar padrões associados ao churn.\n",
    "\n",
    "A análise exploratória é fundamental para:\n",
    "- validar hipóteses de negócio,\n",
    "- identificar relações relevantes entre variáveis,\n",
    "- detectar possíveis problemas de desbalanceamento,\n",
    "- e orientar decisões futuras de modelagem e feature engineering.\n",
    "\n",
    "Todas as análises foram feitas considerando o dataset já tratado, garantindo consistência e evitando vieses decorrentes de problemas de qualidade dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb23a63-1885-4679-b68d-0caa5062001a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição do target\n",
    "churn_dist = df_clean[\"Churn\"].value_counts()\n",
    "churn_pct = df_clean[\"Churn\"].value_counts(normalize=True) * 100\n",
    "\n",
    "display(pd.DataFrame({\n",
    "    \"Quantidade\": churn_dist,\n",
    "    \"Percentual (%)\": churn_pct.round(2)\n",
    "}))\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(churn_dist.index.astype(str), churn_dist.values)\n",
    "plt.title(\"Distribuição do Churn\")\n",
    "plt.xlabel(\"Churn\")\n",
    "plt.ylabel(\"Quantidade de Clientes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb17848-0ddd-407c-9db2-c7dbdecbbdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3.1 Distribuição do Churn\n",
    "\n",
    "A análise da variável alvo mostrou que a base apresenta um **desbalanceamento moderado**, com a maioria dos clientes não cancelando o serviço.\n",
    "\n",
    "Esse ponto é relevante, pois modelos treinados sem atenção a esse desbalanceamento podem aprender a favorecer a classe majoritária, reduzindo a capacidade de identificar corretamente clientes em risco de churn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acca628-0752-4c7f-b1ff-e241af6fe71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taxa média de churn por tipo de contrato\n",
    "churn_contrato = (\n",
    "    df_clean\n",
    "    .groupby(\"Tipo_Contrato\")[\"Churn_bin\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "display(churn_contrato)\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(churn_contrato[\"Tipo_Contrato\"], churn_contrato[\"Churn_bin\"])\n",
    "plt.title(\"Taxa de Churn por Tipo de Contrato\")\n",
    "plt.ylabel(\"Taxa de Churn\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c00bcd-a4e5-4617-b4e7-25d7ae1c9e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3.2 Churn por Tipo de Contrato\n",
    "\n",
    "Ao analisar a taxa média de churn por tipo de contrato, observei que clientes com **contratos mensais** apresentam uma probabilidade de cancelamento significativamente maior do que aqueles com contratos de maior duração.\n",
    "\n",
    "Esse resultado está alinhado com a lógica de negócio, pois contratos mais longos criam maior compromisso do cliente com a empresa, reduzindo a propensão ao churn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a177560a-82ef-43dc-a0e4-272937fed28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning do tempo como cliente\n",
    "df_clean[\"Faixa_Tempo\"] = pd.cut(\n",
    "    df_clean[\"Tempo_como_Cliente\"],\n",
    "    bins=[0, 6, 12, 24, 48, 72],\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "churn_tempo = (\n",
    "    df_clean\n",
    "    .groupby(\"Faixa_Tempo\")[\"Churn_bin\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "display(churn_tempo)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(churn_tempo[\"Faixa_Tempo\"].astype(str), churn_tempo[\"Churn_bin\"], marker=\"o\")\n",
    "plt.title(\"Taxa de Churn por Tempo como Cliente\")\n",
    "plt.xlabel(\"Tempo como Cliente (meses)\")\n",
    "plt.ylabel(\"Taxa de Churn\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1c8281-badf-4076-b52c-7519dc4857ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Durante a análise, eu identifiquei que a variável `Churn` estava em formato categórico (texto), o que impedia o cálculo de médias por grupo.  \n",
    "Para resolver isso, eu criei uma variável auxiliar `Churn_bin`, mapeando churn para valores binários (0 e 1).  \n",
    "\n",
    "Essa abordagem é estatisticamente adequada porque a **média de uma variável binária** representa diretamente a **taxa/probabilidade empírica** de churn em cada grupo analisado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348bacfc-2fed-40ae-86f5-9d0805436f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação de faixas de pagamento mensal\n",
    "df_clean[\"Faixa_Pagamento\"] = pd.qcut(\n",
    "    df_clean[\"Pagamento_Mensal\"],\n",
    "    q=4,\n",
    "    duplicates=\"drop\"\n",
    ")\n",
    "\n",
    "churn_pagamento = (\n",
    "    df_clean\n",
    "    .groupby(\"Faixa_Pagamento\")[\"Churn_bin\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "display(churn_pagamento)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(\n",
    "    churn_pagamento[\"Faixa_Pagamento\"].astype(str),\n",
    "    churn_pagamento[\"Churn_bin\"],\n",
    "    marker=\"o\"\n",
    ")\n",
    "plt.title(\"Taxa de Churn por Faixa de Pagamento Mensal\")\n",
    "plt.xlabel(\"Faixa de Pagamento Mensal\")\n",
    "plt.ylabel(\"Taxa de Churn\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8406bfc4-4eee-46c1-b46f-f73da728fae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3.3 Churn e Pagamento Mensal\n",
    "\n",
    "A análise mostrou que clientes que pagam valores mensais mais elevados apresentam uma taxa de churn maior.\n",
    "\n",
    "Esse comportamento pode estar associado à sensibilidade a preço ou à percepção de que o custo do serviço não está alinhado ao valor entregue, indicando uma oportunidade de ação para estratégias de retenção focadas nesse perfil de cliente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61175995-3fbb-478f-866a-c025c186ce92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Pré-processamento para Modelagem\n",
    "\n",
    "Nesta etapa, eu preparei os dados para a etapa de modelagem preditiva.  \n",
    "O foco foi transformar as variáveis em um formato adequado para algoritmos de machine learning, garantindo que o processo fosse feito de maneira organizada e sem vazamento de informação.\n",
    "\n",
    "As decisões de pré-processamento foram tomadas considerando:\n",
    "- o tipo das variáveis (numéricas e categóricas),\n",
    "- a interpretabilidade do modelo,\n",
    "- e a necessidade de manter consistência entre treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bcc1bf-3a39-43ef-9a69-a25ffe9c90a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target final (binário)\n",
    "y = df_clean[\"Churn_bin\"]\n",
    "\n",
    "# Removendo colunas que não devem entrar no modelo\n",
    "colunas_excluir = [\n",
    "    \"Churn\",        # versão textual do target\n",
    "    \"Churn_bin\",    # target (não entra como feature)\n",
    "    \"customerID\",   # identificador\n",
    "    \"Faixa_Tempo\",  # criada apenas para EDA\n",
    "    \"Faixa_Pagamento\"\n",
    "]\n",
    "\n",
    "X = df_clean.drop(columns=colunas_excluir, errors=\"ignore\")\n",
    "\n",
    "print(\"Shape X:\", X.shape)\n",
    "print(\"Shape y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bda380a-2a81-41d2-aa4c-26c67ad66bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Antes do encoding, eu analisei os tipos de variáveis para separar corretamente variáveis numéricas e categóricas.  \n",
    "Essa separação é importante porque cada tipo exige um tratamento específico durante o pré-processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9153d03-1de7-4829-8b7d-499fcc6b52a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis numéricas e categóricas\n",
    "num_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "cat_features = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "print(\"Numéricas:\", num_features)\n",
    "print(\"Categóricas:\", cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e371ea-6dca-4df7-9ec9-4fc46259f619",
   "metadata": {},
   "outputs": [],
   "source": [
    "Para as variáveis categóricas, optei por utilizar **One-Hot Encoding**, pois:\n",
    "- a base possui cardinalidade baixa a moderada,\n",
    "- os modelos escolhidos conseguem lidar bem com esse tipo de codificação,\n",
    "- e essa abordagem facilita a interpretação dos resultados.\n",
    "\n",
    "As variáveis numéricas foram mantidas em sua escala original nesta etapa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7077786-7d0c-4cb5-9ce6-5510135508cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Treino:\", X_train.shape, \"Teste:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32282c04-1ede-4ee9-8039-c7977c1171c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(\n",
    "    drop=\"first\",\n",
    "    handle_unknown=\"ignore\",\n",
    "    sparse_output=False\n",
    ")\n",
    "\n",
    "# Fit apenas no treino\n",
    "X_train_cat = encoder.fit_transform(X_train[cat_features])\n",
    "X_test_cat = encoder.transform(X_test[cat_features])\n",
    "\n",
    "# DataFrames codificados\n",
    "X_train_cat = pd.DataFrame(\n",
    "    X_train_cat,\n",
    "    columns=encoder.get_feature_names_out(cat_features),\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "X_test_cat = pd.DataFrame(\n",
    "    X_test_cat,\n",
    "    columns=encoder.get_feature_names_out(cat_features),\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "# Numéricos\n",
    "X_train_num = X_train[num_features]\n",
    "X_test_num = X_test[num_features]\n",
    "\n",
    "# Dataset final\n",
    "X_train_final = pd.concat([X_train_num, X_train_cat], axis=1)\n",
    "X_test_final = pd.concat([X_test_num, X_test_cat], axis=1)\n",
    "\n",
    "print(\"Shape final treino:\", X_train_final.shape)\n",
    "print(\"Shape final teste:\", X_test_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a14066-3902-46f4-966c-94d4c1a9efaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nota técnica: devido à versão do scikit-learn utilizada, o parâmetro `sparse` do OneHotEncoder foi substituído por `sparse_output`. O ajuste foi feito para garantir compatibilidade com versões mais recentes da biblioteca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fd2689-bc18-4ae5-b75a-b57bb55a4c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Pré-processamento para Modelagem\n",
    "\n",
    "Nesta etapa, eu preparei os dados para a construção dos modelos de machine learning.  \n",
    "O objetivo foi transformar as variáveis em um formato adequado para os algoritmos, garantindo consistência, reprodutibilidade e evitando vazamento de informações entre os conjuntos de treino e teste.\n",
    "\n",
    "Inicialmente, defini a variável alvo (`Churn`) em formato binário, criando a coluna `Churn_bin`, que representa se o cliente cancelou (1) ou não (0) o serviço. Essa transformação foi essencial para permitir o uso de métricas e modelos de classificação.\n",
    "\n",
    "Em seguida, removi colunas que não deveriam entrar no modelo, como identificadores únicos e variáveis criadas exclusivamente para análise exploratória, evitando que informações irrelevantes ou derivadas influenciassem o treinamento.\n",
    "\n",
    "As variáveis explicativas foram então separadas em **numéricas** e **categóricas**, pois cada tipo exige um tratamento específico.  \n",
    "Para as variáveis categóricas, utilizei **One-Hot Encoding**, uma técnica amplamente empregada em problemas de classificação e adequada para variáveis com baixa a média cardinalidade. O processo de encoding foi ajustado para a versão do scikit-learn utilizada, garantindo compatibilidade técnica.\n",
    "\n",
    "A separação dos dados em conjuntos de treino e teste foi realizada de forma **estratificada**, preservando a proporção da variável alvo e assegurando uma avaliação mais confiável do modelo.\n",
    "\n",
    "Ao final desta etapa, obtive conjuntos de dados de treino e teste totalmente preparados para a etapa de modelagem, com todas as variáveis em formato numérico e alinhadas entre si, permitindo o treinamento de modelos de machine learning de forma segura e eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4793b777-875a-4314-9790-69f7cccbc193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Modelagem Preditiva\n",
    "\n",
    "Nesta etapa, eu desenvolvi modelos de machine learning com o objetivo de prever o churn dos clientes.  \n",
    "A modelagem foi iniciada com um modelo baseline simples, utilizado como referência mínima de desempenho.\n",
    "\n",
    "Em seguida, construí um modelo de classificação mais robusto, buscando equilibrar desempenho preditivo e interpretabilidade, características importantes para aplicações reais de negócio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bd24a8-5e83-40aa-8aaf-c7a5f83e31b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Baseline: sempre prever a classe majoritária\n",
    "baseline = DummyClassifier(strategy=\"most_frequent\", random_state=42)\n",
    "baseline.fit(X_train_final, y_train)\n",
    "\n",
    "y_pred_baseline = baseline.predict(X_test_final)\n",
    "\n",
    "print(\"Baseline Accuracy:\", accuracy_score(y_test, y_pred_baseline))\n",
    "print(\"\\nClassification Report - Baseline\")\n",
    "print(classification_report(y_test, y_pred_baseline))\n",
    "\n",
    "confusion_matrix(y_test, y_pred_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee125a55-8256-4316-985a-476c7d0fc966",
   "metadata": {},
   "outputs": [],
   "source": [
    "O modelo baseline, que sempre prevê a classe majoritária, apresentou uma acurácia elevada devido ao desbalanceamento da base.  \n",
    "No entanto, ele falha completamente em identificar clientes que realmente entram em churn, o que o torna inadequado para uso prático.\n",
    "\n",
    "Esse resultado reforça a necessidade de um modelo mais sofisticado, capaz de capturar padrões associados ao cancelamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb94b97-47cb-4206-a8a0-1735cf7691a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\",  # importante para churn\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "log_reg.fit(X_train_final, y_train)\n",
    "\n",
    "y_pred = log_reg.predict(X_test_final)\n",
    "y_proba = log_reg.predict_proba(X_test_final)[:, 1]\n",
    "\n",
    "print(\"Classification Report - Logistic Regression\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46870ebd-c656-41d2-8cc1-f2121a962911",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_proba)\n",
    "print(\"ROC-AUC:\", round(roc_auc, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1ad7c1-8c07-430b-8b5b-b6239175b186",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Curva ROC - Regressão Logística\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0000ca-c58c-407e-915b-10fc6da9d8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "O modelo de Regressão Logística apresentou desempenho significativamente superior ao baseline, especialmente na identificação de clientes propensos ao churn.\n",
    "\n",
    "A métrica ROC-AUC indica que o modelo possui boa capacidade de separação entre clientes que cancelam e os que permanecem ativos, mesmo considerando o desbalanceamento da base.\n",
    "\n",
    "Além disso, a Regressão Logística oferece interpretabilidade, permitindo entender como diferentes variáveis influenciam a probabilidade de churn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4dca5f-6587-42e0-b830-efe9a894f352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coeficientes do modelo\n",
    "coeficientes = pd.DataFrame({\n",
    "    \"Feature\": X_train_final.columns,\n",
    "    \"Coeficiente\": log_reg.coef_[0]\n",
    "}).sort_values(by=\"Coeficiente\", ascending=False)\n",
    "\n",
    "display(coeficientes.head(10))\n",
    "display(coeficientes.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1940d6e9-0e1b-40ef-915e-09eca43d2739",
   "metadata": {},
   "outputs": [],
   "source": [
    "A análise dos coeficientes do modelo mostrou que variáveis relacionadas a tipo de contrato, tempo como cliente e valor do pagamento mensal possuem forte influência na probabilidade de churn.\n",
    "\n",
    "Esses resultados estão alinhados com os insights obtidos na análise exploratória, reforçando a consistência do modelo e sua aplicabilidade para apoiar decisões estratégicas de retenção de clientes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233a79ee-f418-4488-969d-039b5d44f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Resultados e Avaliação do Modelo\n",
    "\n",
    "Nesta etapa, eu consolidei os principais resultados obtidos com o modelo de machine learning desenvolvido para predição de churn.\n",
    "\n",
    "A avaliação foi realizada utilizando métricas adequadas para problemas de classificação com classes desbalanceadas, com foco especial na capacidade do modelo de identificar clientes propensos ao cancelamento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c8685c-d293-4ddd-88ed-8166943268d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6.1 Desempenho do Modelo\n",
    "\n",
    "O modelo de Regressão Logística apresentou desempenho significativamente superior ao modelo baseline, demonstrando capacidade real de identificar padrões associados ao churn.\n",
    "\n",
    "Os principais destaques foram:\n",
    "- Desempenho consistente na separação entre clientes que cancelam e os que permanecem ativos, conforme evidenciado pela curva ROC.\n",
    "- Melhora substancial na identificação da classe minoritária (churn), quando comparado ao baseline.\n",
    "- Resultados alinhados com os insights observados durante a análise exploratória.\n",
    "\n",
    "Esses resultados indicam que o modelo é adequado como ponto de partida para apoiar estratégias de retenção de clientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652e8ac3-06bf-46a1-ba06-2a0a94de3a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6.2 Visualização dos Resultados\n",
    "\n",
    "Para facilitar a interpretação dos resultados, utilizei visualizações gráficas que permitem avaliar o desempenho do modelo e os fatores mais relevantes para a previsão de churn.\n",
    "\n",
    "As principais visualizações apresentadas foram:\n",
    "- Curva ROC, demonstrando a capacidade de discriminação do modelo.\n",
    "- Matriz de confusão, permitindo avaliar acertos e erros de classificação.\n",
    "- Análise dos coeficientes da Regressão Logística, destacando as variáveis com maior impacto na probabilidade de churn.\n",
    "\n",
    "Essas visualizações tornam os resultados mais acessíveis e facilitam a comunicação com stakeholders técnicos e de negócio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566b0d55-138a-4a3d-a109-42cb1033fc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Conclusões\n",
    "\n",
    "Ao longo deste projeto, eu desenvolvi uma solução de Ciência de Dados voltada para a predição de churn em uma empresa de telecomunicações.\n",
    "\n",
    "A análise exploratória revelou que o churn está fortemente associado a fatores como:\n",
    "- tipo de contrato,\n",
    "- tempo como cliente,\n",
    "- e valor do pagamento mensal.\n",
    "\n",
    "O modelo de machine learning desenvolvido foi capaz de capturar esses padrões e apresentou desempenho superior ao baseline, demonstrando potencial para apoiar decisões estratégicas de retenção de clientes.\n",
    "\n",
    "Apesar dos bons resultados, este projeto representa uma primeira abordagem. Modelos mais complexos e dados adicionais podem contribuir para ganhos adicionais de performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b255f34f-17e7-4f25-ac88-b1aafac3db32",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7.1 Próximos Passos\n",
    "\n",
    "Como continuidade deste projeto, algumas melhorias possíveis incluem:\n",
    "- Testar modelos mais avançados, como Random Forest ou Gradient Boosting.\n",
    "- Ajustar hiperparâmetros para otimização de desempenho.\n",
    "- Avaliar técnicas de balanceamento de classes.\n",
    "- Incorporar dados comportamentais mais detalhados.\n",
    "- Implementar o modelo em ambiente produtivo para monitoramento contínuo de churn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
